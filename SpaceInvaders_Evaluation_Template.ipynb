{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpaceInvaders Evaluation Template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQsuX0CsGQiq",
        "colab_type": "text"
      },
      "source": [
        "# Space Invaders\n",
        "\n",
        "# Weights & Biases x Qualcomm - SpaceInvaders Challenge\n",
        "\n",
        "This notebook contains code for loading models from a file saved in a wandb run, and evaluating the model.\n",
        "\n",
        "For more details on the SpaceInvaders challenge, please visit the [competition website](https://app.wandb.ai/wandb/spaceinvaders-challenge/benchmark/).\n",
        "\n",
        "![](https://thumbs.gfycat.com/CookedFriendlyAntarcticfurseal-size_restricted.gif)\n",
        "\n",
        "## Running this notebook\n",
        "1. Click \"Open in playground\" to create a copy of this notebook for yourself.\n",
        "2. Save a copy in Google Drive for yourself.\n",
        "3. To enable a GPU, please click Edit > Notebook Settings. Change the \"hardware accelerator\" to GPU.\n",
        "4. Step through each section, pressing play on the code blocks to run the cells.\n",
        "5. Add your own model code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlzpxEOsIePf",
        "colab_type": "text"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "Please replace the model file (`model.h5`) and run_path (`username/project_name/run_name`) with your submissions model file and run_path respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrVri-RnXD2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restore a model file from a specific run by user \"lavanyashukla\" in project \"qualcomm\" from run \"mnswzdre\"\n",
        "fname = \"model.h5\"\n",
        "run_path=\"lavanyashukla/qualcomm/b0qh2jcw\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkNyJEmQRWOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade wandb -qq\n",
        "# import wandb\n",
        "import wandb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maz6vvi5HlAp",
        "colab_type": "code",
        "outputId": "d451d63b-8fee-42ad-ace3-d35a732a1f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# restore model\n",
        "api = wandb.Api()\n",
        "run = api.run(run_path)\n",
        "local_path = None\n",
        "with run.file(fname).download(replace=True) as f:\n",
        "  local_path = f.name\n",
        "agent = load_model(local_path)\n",
        "agent.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ8AMc_zWCnS",
        "colab_type": "text"
      },
      "source": [
        "## Setup and Preproceesing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvHkMNUGGKCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym pyvirtualdisplay -qq\n",
        "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
        "!pip install xdpyinfo -qq\n",
        "\n",
        "!apt-get update -qq\n",
        "!apt-get install cmake -qq\n",
        "!pip install --upgrade setuptools -qq\n",
        "!pip install ez_setup -qq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDpK4FdgHHsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(30)\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "import cv2\n",
        "import base64\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "import keras\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HN-f-hFHMeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "color = np.array([210, 164, 74]).mean()\n",
        "\n",
        "def preprocess_frame(obs):\n",
        "    img = obs\n",
        "\n",
        "    # Convert to greyscale\n",
        "    img = img.mean(axis=2)\n",
        "\n",
        "    # Improve contrast\n",
        "    img[img==color] = 0\n",
        "\n",
        "    # Normalzie image\n",
        "    img = (img - 128) / 128 - 1\n",
        "\n",
        "    # Reshape to 80*80*1\n",
        "    img = img.reshape(160, 210)\n",
        "\n",
        "    return img "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwt-wy0NWHuH",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIZiiAW6HTil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# **** Caution: Do not modify this cell ****\n",
        "# initialize total reward across episodes\n",
        "cumulative_reward = 0\n",
        "episode = 0\n",
        "\n",
        "def evaluate(episodic_reward, reset=False):\n",
        "  '''\n",
        "  Takes in the reward for an episode, calculates the cumulative_avg_reward\n",
        "    and logs it in wandb. If episode > 100, stops logging scores to wandb.\n",
        "    Called after playing each episode. See example below.\n",
        "\n",
        "  Arguments:\n",
        "    episodic_reward - reward received after playing current episode\n",
        "  '''\n",
        "  global episode\n",
        "  global cumulative_reward\n",
        "  if reset:\n",
        "    cumulative_reward = 0\n",
        "    episode = 0\n",
        "    \n",
        "  episode += 1\n",
        "  print(\"Episode: %d\"%(episode))\n",
        "\n",
        "  # your models will be evaluated on 100-episode average reward\n",
        "  # therefore, we stop logging after 100 episodes\n",
        "  if (episode > 100):\n",
        "    print(\"Scores from episodes > 100 won't be logged in wandb.\")\n",
        "    return\n",
        "\n",
        "  # log total reward received in this episode to wandb\n",
        "  wandb.log({'episodic_reward': episodic_reward})\n",
        "\n",
        "  # add reward from this episode to cumulative_reward\n",
        "  cumulative_reward += episodic_reward\n",
        "\n",
        "  # calculate the cumulative_avg_reward\n",
        "  # this is the metric your models will be evaluated on\n",
        "  cumulative_avg_reward = cumulative_reward/episode\n",
        "\n",
        "  # log cumulative_avg_reward over all episodes played so far\n",
        "  wandb.log({'cumulative_avg_reward': cumulative_avg_reward})\n",
        "\n",
        "  return cumulative_avg_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDCVUIhxWL-n",
        "colab_type": "text"
      },
      "source": [
        "## Play the game for 100 episodes, log cumulative average reward, for 5 different values of seed\n",
        "\n",
        "Please adjust this as needed to work with your model architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHyYmf2AHWBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "from tensorflow import set_random_seed\n",
        "\n",
        "cumulative_avg_rewards = []\n",
        "for seed_ in [10, 50, 100, 200, 500]:\n",
        "  seed(seed_)\n",
        "  set_random_seed(seed_)\n",
        "  print(\"Seed: \",seed_)\n",
        "  episode = 0\n",
        "\n",
        "  # initialize environment\n",
        "  env = gym.make('SpaceInvaders-v0')\n",
        "  state_size = env.observation_space.shape[0]\n",
        "  action_size = env.action_space.n\n",
        "  print(\"Actions available(%d): %r\"%(env.action_space.n, env.env.get_action_meanings()))\n",
        "\n",
        "  # initialize a new wandb run\n",
        "  wandb.init(project=\"qualcomm-evaluation\")\n",
        "\n",
        "  # define hyperparameters\n",
        "  wandb.config.episodes = 100\n",
        "  wandb.config.runpath = run_path\n",
        "\n",
        "  # record gameplay video\n",
        "  display = Display(visible=0, size=(1400, 900))\n",
        "  display.start()\n",
        "\n",
        "  # run for 100 episodes\n",
        "  # Note: Please adjust this as needed to work with your model architecture.\n",
        "  # Make sure you still call evaluate() with the reward received in each episode\n",
        "  for i in range(wandb.config.episodes):\n",
        "    # Set reward received in this episode = 0 at the start of the episode\n",
        "    episodic_reward = 0\n",
        "    reset = False\n",
        "\n",
        "    # record a video of the game using wrapper\n",
        "    env = gym.wrappers.Monitor(env, './video', force=True)\n",
        "    \n",
        "    # play a random game\n",
        "    state = env.reset()\n",
        "    state = preprocess_frame(state)\n",
        "\n",
        "    done = False\n",
        "    action_count = 0\n",
        "    while not done:\n",
        "      # get prediction for next action from model\n",
        "      actions = agent.predict(state)\n",
        "      action = np.argmax(actions, axis=-1)\n",
        "      action = np.argmax(action)\n",
        "\n",
        "      # perform the action and fetch next state, reward\n",
        "      next_state, reward, done, _ = env.step(action)\n",
        "      next_state = preprocess_frame(next_state)\n",
        "      state = next_state\n",
        "\n",
        "      action_count += 1\n",
        "      if(action_count == 50):\n",
        "        done = True\n",
        "        break\n",
        "\n",
        "      episodic_reward += reward\n",
        "    \n",
        "    # call evaluation function - takes in reward received after playing an episode\n",
        "    # calculates the cumulative_avg_reward over 100 episodes & logs it in wandb\n",
        "    if(i==0):\n",
        "      reset = True\n",
        "\n",
        "    cumulative_avg_reward = evaluate(episodic_reward, reset)\n",
        "\n",
        "    # your models will be evaluated on 100-episode average reward\n",
        "    # therefore, we stop logging after 100 episodes\n",
        "    if (i >= 99):\n",
        "      cumulative_avg_rewards.append(cumulative_avg_reward)\n",
        "      break\n",
        "\n",
        "    record_video = False\n",
        "    env.close() \n",
        "\n",
        "    # render gameplay video\n",
        "    if (i %50 == 0):\n",
        "      mp4list = glob.glob('video/*.mp4')\n",
        "      if len(mp4list) > 0:\n",
        "        print(len(mp4list))\n",
        "        mp4 = mp4list[-1]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "\n",
        "        # log gameplay video in wandb\n",
        "        wandb.log({\"gameplays\": wandb.Video(mp4, fps=4, format=\"gif\")})\n",
        "\n",
        "        # display gameplay video\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(encoded.decode('ascii'))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-irjWcYDAE",
        "colab_type": "text"
      },
      "source": [
        "# Final score\n",
        "The final score is evaluated as the cumulative_avg_reward, averaged across 5 seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKiJcC0WJ4W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Final score: \", np.mean(cumulative_avg_rewards))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}